(venv) mike@mac cs489-final % python3 fine_tune_text_model.py
Fine-tuning CLIP text encoder against frozen image embeddings...
Loaded 44427 products

Fold 1/5
    200/889
    400/889
    600/889
    800/889
  Epoch 1: Train=0.8548, Val=0.6922 (538.1s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 2: Train=0.6366, Val=0.6112 (550.3s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 3: Train=0.5782, Val=0.5712 (528.6s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 4: Train=0.5403, Val=0.5478 (501.9s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 5: Train=0.5174, Val=0.5289 (502.8s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 6: Train=0.4930, Val=0.5159 (501.9s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 7: Train=0.4800, Val=0.5039 (502.0s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 8: Train=0.4642, Val=0.4947 (499.3s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 9: Train=0.4527, Val=0.4866 (501.8s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 10: Train=0.4373, Val=0.4805 (501.5s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 11: Train=0.4287, Val=0.4749 (502.5s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 12: Train=0.4201, Val=0.4685 (502.0s)
Updated best model

Fold 2/5
    200/889
    400/889
    600/889
    800/889
  Epoch 1: Train=0.8573, Val=0.6861 (477.1s)
    200/889
    400/889
    600/889
    800/889
  Epoch 2: Train=0.6380, Val=0.6055 (475.4s)
    200/889
    400/889
    600/889
    800/889
  Epoch 3: Train=0.5747, Val=0.5665 (476.4s)
    200/889
    400/889
    600/889
    800/889
  Epoch 4: Train=0.5419, Val=0.5401 (474.4s)
    200/889
    400/889
    600/889
    800/889
  Epoch 5: Train=0.5179, Val=0.5226 (474.7s)
    200/889
    400/889
    600/889
    800/889
  Epoch 6: Train=0.4959, Val=0.5106 (475.8s)
    200/889
    400/889
    600/889
    800/889
  Epoch 7: Train=0.4795, Val=0.4978 (476.9s)
    200/889
    400/889
    600/889
    800/889
  Epoch 8: Train=0.4621, Val=0.4882 (479.6s)
    200/889
    400/889
    600/889
    800/889
  Epoch 9: Train=0.4513, Val=0.4803 (475.2s)
    200/889
    400/889
    600/889
    800/889
  Epoch 10: Train=0.4418, Val=0.4740 (469.5s)
    200/889
    400/889
    600/889
    800/889
  Epoch 11: Train=0.4278, Val=0.4673 (471.4s)
Updated best model
    200/889
    400/889
    600/889
    800/889
  Epoch 12: Train=0.4205, Val=0.4625 (470.3s)
Updated best model

Fold 3/5
    200/889
    400/889
    600/889
    800/889
  Epoch 1: Train=0.8508, Val=0.6913 (464.8s)
    200/889
    400/889
    600/889
    800/889
  Epoch 2: Train=0.6381, Val=0.6109 (464.3s)
    200/889
    400/889
    600/889
    800/889
  Epoch 3: Train=0.5730, Val=0.5699 (467.7s)
    200/889
    400/889
    600/889
    800/889
  Epoch 4: Train=0.5405, Val=0.5448 (466.9s)
    200/889
    400/889
    600/889
    800/889
  Epoch 5: Train=0.5134, Val=0.5249 (463.4s)
    200/889
    400/889
    600/889
    800/889
  Epoch 6: Train=0.4967, Val=0.5113 (466.9s)
    200/889
    400/889
    600/889
    800/889
  Epoch 7: Train=0.4787, Val=0.4995 (469.9s)
    200/889
    400/889
    600/889
    800/889
  Epoch 8: Train=0.4659, Val=0.4908 (466.8s)
    200/889
    400/889
    600/889
    800/889
  Epoch 9: Train=0.4553, Val=0.4833 (468.7s)
    200/889
    400/889
    600/889
    800/889
  Epoch 10: Train=0.4433, Val=0.4756 (467.7s)
    200/889
    400/889
    600/889
    800/889
  Epoch 11: Train=0.4312, Val=0.4691 (469.7s)
    200/889
    400/889
    600/889
    800/889
  Epoch 12: Train=0.4246, Val=0.4664 (467.3s)

Fold 4/5
    200/889
    400/889
    600/889
    800/889
  Epoch 1: Train=0.8569, Val=0.6849 (462.5s)
    200/889
    400/889
    600/889
    800/889
  Epoch 2: Train=0.6387, Val=0.6051 (463.4s)
    200/889
    400/889
    600/889
    800/889
  Epoch 3: Train=0.5748, Val=0.5659 (459.6s)
    200/889
    400/889
    600/889
    800/889
  Epoch 4: Train=0.5399, Val=0.5409 (460.4s)
    200/889
    400/889
    600/889
    800/889
  Epoch 5: Train=0.5187, Val=0.5228 (462.2s)
    200/889
    400/889
    600/889
    800/889
  Epoch 6: Train=0.4945, Val=0.5076 (462.0s)
    200/889
    400/889
    600/889
    800/889
  Epoch 7: Train=0.4784, Val=0.4974 (460.8s)
    200/889
    400/889
    600/889
    800/889
  Epoch 8: Train=0.4658, Val=0.4885 (462.4s)
    200/889
    400/889
    600/889
    800/889
  Epoch 9: Train=0.4547, Val=0.4794 (466.6s)
    200/889
    400/889
    600/889
    800/889
  Epoch 10: Train=0.4418, Val=0.4742 (466.9s)
    200/889
    400/889
    600/889
    800/889
  Epoch 11: Train=0.4291, Val=0.4676 (467.8s)
    200/889
    400/889
    600/889
    800/889
  Epoch 12: Train=0.4219, Val=0.4611 (471.2s)
Updated best model

Fold 5/5
    200/889
    400/889
    600/889
    800/889
  Epoch 1: Train=0.8531, Val=0.6882 (441.6s)
    200/889
    400/889
    600/889
    800/889
  Epoch 2: Train=0.6381, Val=0.6081 (440.6s)
    200/889
    400/889
    600/889
    800/889
  Epoch 3: Train=0.5769, Val=0.5679 (438.9s)
    200/889
    400/889
    600/889
    800/889
  Epoch 4: Train=0.5382, Val=0.5440 (439.0s)
    200/889
    400/889
    600/889
    800/889
  Epoch 5: Train=0.5141, Val=0.5249 (438.5s)
    200/889
    400/889
    600/889
    800/889
  Epoch 6: Train=0.4942, Val=0.5108 (440.0s)
    200/889
    400/889
    600/889
    800/889
  Epoch 7: Train=0.4779, Val=0.5008 (440.3s)
    200/889
    400/889
    600/889
    800/889
  Epoch 8: Train=0.4656, Val=0.4896 (439.9s)
    200/889
    400/889
    600/889
    800/889
  Epoch 9: Train=0.4510, Val=0.4828 (438.6s)
    200/889
    400/889
    600/889
    800/889
  Epoch 10: Train=0.4410, Val=0.4735 (436.1s)
    200/889
    400/889
    600/889
    800/889
  Epoch 11: Train=0.4306, Val=0.4703 (436.1s)
    200/889
    400/889
    600/889
    800/889
  Epoch 12: Train=0.4222, Val=0.4627 (436.5s)
Finishing training



Average val loss: 0.4642
Fold 1 val loss: 0.4685
Fold 2 val loss: 0.4625
Fold 3 val loss: 0.4664
Fold 4 val loss: 0.4611
Fold 5 val loss: 0.4627
(venv) mike@mac cs489-final % 
